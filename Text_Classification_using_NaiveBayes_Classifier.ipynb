{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praveen76/Text-Classification-using-NaiveBayes-Classifier/blob/main/Text_Classification_using_NaiveBayes_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_b5pYsPY7f3"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7sU_4_aZASD"
      },
      "source": [
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "* perform different text processing techniques such as removing html strips and noise text, removing special characters, lemmatization, stemming, tokenization, removing stop words\n",
        "* train and evaluate a Naive Bayes model from the sklearn ML library, to predict the sentiment ('positive' or 'negative') for a movie reviews dataset\n",
        "* use the gradio library  to generate a customizable UI for displaying the predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ9aiXQDBQ-r"
      },
      "source": [
        "## Dataset description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEarccunBsDs"
      },
      "source": [
        "The [IMDB Movie Reviews dataset](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) is a binary sentiment analysis dataset consisting of 50,000 reviews from the Internet Movie Database (IMDb) labeled as positive or negative. The dataset contains an even number of positive and negative reviews. Only highly polarizing reviews are considered. A negative review has a score ≤ 4 out of 10, and a positive review has a score ≥ 7 out of 10. No more than 30 reviews are included per movie. The dataset contains additional unlabeled data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZLYIcdJffR4"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY9tgfHgffSY"
      },
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Hlj81lsuffSZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "41559031-12ba-4afd-eb34-ef8214f062b9"
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M5_AST_01_TextClassification_using_NaiveBayes_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "\n",
        "    ipython.magic(\"sx wget https://cdn.iisc.talentsprint.com/CDS/Datasets/IMDB_Dataset.csv\")\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://aimlops-iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2302112&recordId=2646\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5VyFvjMT5O-"
      },
      "source": [
        "### Importing Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZWtHdmPYMOvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bb72652-3bdc-4583-a4f7-18bbf875e2b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer                        # to transform a given text into a vector on the basis of the frequency (count) of each word that occurs in the entire text\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer                        # to transform text into a term and document frequency based representation of numbers\n",
        "import nltk                                                                        # platform for building Python programs to process natural language\n",
        "nltk.download('stopwords')                                                         # to download the stop words\n",
        "nltk.download('punkt')                                                             # tokenizer divides a text into a list of sentences, by using an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences\n",
        "nltk.download('wordnet')                                                           # to lemmatize word using WordNet's built-in function\n",
        "from nltk.corpus import stopwords                                                  # importing the NTLK stopwords to remove articles, preposition and other words that are not actionable\n",
        "from nltk.stem.porter import PorterStemmer                                         # process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words\n",
        "from wordcloud import WordCloud                                                    # visualization of words based on their frequency\n",
        "from nltk.tokenize import word_tokenize                                            # allows to create individual objects from a bag of words\n",
        "from bs4 import BeautifulSoup                                                      # Python library for pulling data from HTML and XML files\n",
        "import re                                                                          # regular expression (or RE) specifies a set of strings that matches it\n",
        "from sklearn.naive_bayes import MultinomialNB                                      # to import multinomial naive bayes which is suitable for classification with discrete features (e.g., word counts for text classification)\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score  # to import metrics for evaluating the classification model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7bG2m775ba6"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v_fAB1U0fqJ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "c1585058-68f9-412d-f82a-61b42301e008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "5  Probably my all-time favorite movie, a story o...  positive\n",
              "6  I sure would like to see a resurrection of a u...  positive\n",
              "7  This show was an amazing, fresh & innovative i...  negative\n",
              "8  Encouraged by the positive comments about this...  negative\n",
              "9  If you like original gut wrenching laughter yo...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5e8a773-2011-4bca-94b6-7edb097f41f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Probably my all-time favorite movie, a story o...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I sure would like to see a resurrection of a u...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Encouraged by the positive comments about this...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>If you like original gut wrenching laughter yo...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5e8a773-2011-4bca-94b6-7edb097f41f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c5e8a773-2011-4bca-94b6-7edb097f41f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c5e8a773-2011-4bca-94b6-7edb097f41f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-541c1950-28bf-49ab-a84d-f124d4df48d0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-541c1950-28bf-49ab-a84d-f124d4df48d0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-541c1950-28bf-49ab-a84d-f124d4df48d0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# read the dataset\n",
        "df = pd.read_csv('IMDB_Dataset.csv')\n",
        "print(df.shape)\n",
        "df.head(10)      # first 10 rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy2WsjbRDCJr"
      },
      "source": [
        "### Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "z8mLwZe5CWSN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "24f6c9b2-ed00-4413-e5c0-f876e93c6322"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   review sentiment\n",
              "count                                               50000     50000\n",
              "unique                                              49582         2\n",
              "top     Loved today's show!!! It was a variety and not...  positive\n",
              "freq                                                    5     25000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c38d731c-420f-4fa0-9607-1bb41b545bf3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50000</td>\n",
              "      <td>50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>49582</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Loved today's show!!! It was a variety and not...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>5</td>\n",
              "      <td>25000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c38d731c-420f-4fa0-9607-1bb41b545bf3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c38d731c-420f-4fa0-9607-1bb41b545bf3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c38d731c-420f-4fa0-9607-1bb41b545bf3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-42a3dfb4-14f5-4daa-afbf-3b7440bff7d8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-42a3dfb4-14f5-4daa-afbf-3b7440bff7d8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-42a3dfb4-14f5-4daa-afbf-3b7440bff7d8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          49582,\n          \"5\",\n          \"50000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          \"25000\",\n          \"50000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# summary of the dataset\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twI5ntekDNrs"
      },
      "source": [
        "Now, we will look at the sentiment count by category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6izwMrUVDQ6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8142ab57-6e01-4ed3-e092-3ee40cd1f1e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    25000\n",
              "negative    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# sentiment count\n",
        "df['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyeDUn36DVRn"
      },
      "source": [
        "We can see that the dataset is balanced.\n",
        "\n",
        "Now, we will do the text cleaning of the reviews.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on2XCsxtI0-b"
      },
      "source": [
        "### Text Cleaning\n",
        "\n",
        "The data scraped from the website is mostly in the raw text form. This data needs to be cleaned before analyzing it or fitting a model to it. Cleaning up the text data is necessary to highlight the attributes that we are going to want our machine learning system to pick up on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tupdRoUSGYrw"
      },
      "source": [
        "**Removing noisy text**\n",
        "\n",
        "Sample noise removal tasks could include:\n",
        "\n",
        "* removing text file headers, footers\n",
        "* removing HTML, XML, etc. markup and metadata\n",
        "* extracting valuable data from other formats, such as JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FzsW7umy6Sea"
      },
      "outputs": [],
      "source": [
        "# removing the html strips\n",
        "def strip_html(text):\n",
        "    # BeautifulSoup is a useful library for extracting data from HTML and XML documents\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "# removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "\n",
        "# removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "x56E-c6KFvZH"
      },
      "outputs": [],
      "source": [
        "# apply function on review column\n",
        "df['review'] = df['review'].apply(denoise_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQzlTJ-VGwVu"
      },
      "source": [
        "**Removing special characters**\n",
        "\n",
        "Special characters typically include any character that is not a letter or number, such as punctuation. Removing special characters from a string results in a string containing only letters and numbers.\n",
        "\n",
        "We can use the `re` python library for Regular expression operations.\n",
        "\n",
        "To know more about Regular expressions, click [here](https://realpython.com/regex-python/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hsi1MZ9X6Xqm"
      },
      "outputs": [],
      "source": [
        "# define function for removing special characters\n",
        "def remove_special_characters(text):\n",
        "    pattern = r'[^a-zA-Z0-9\\s]'\n",
        "    text = re.sub(pattern,'',text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IBWV2c7oGpVL"
      },
      "outputs": [],
      "source": [
        "# apply function on review column\n",
        "df['review'] = df['review'].apply(remove_special_characters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKHDo92_nm-H"
      },
      "source": [
        "**Lemmatization**\n",
        "\n",
        "Lemmatization is a text pre-processing technique used to break a word down to its root meaning or word (called lemme) to identify similarities.\n",
        "\n",
        "For example, a lemmatization algorithm would reduce the word ***better*** to its root word, or lemme, ***good***."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tjqMtkJ9ake5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee54701-81da-41c7-ce31-b3ad816ca146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "better : good\n"
          ]
        }
      ],
      "source": [
        "# Lemmatize word using WordNet's built-in function\n",
        "# pos: The Part Of Speech tag.\n",
        "#      Valid options are \"n\" for nouns, \"v\" for verbs, \"a\" for adjectives,\n",
        "#                        \"r\" for adverbs and \"s\" for satellite adjectives.\n",
        "\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\", ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGsYJGmLG9bM"
      },
      "source": [
        "**Text Stemming**\n",
        "\n",
        "Stemming, also called suffix stripping, is a technique used to reduce text dimensionality. Stemming is also a type of text normalization that enables you to standardize some words into specific expressions also called stems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8R8eAA_b6bOS"
      },
      "outputs": [],
      "source": [
        "# stemming the text\n",
        "def simple_stemmer(text):\n",
        "    ps = nltk.porter.PorterStemmer()\n",
        "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bmBWpKUhG5F7"
      },
      "outputs": [],
      "source": [
        "# apply function on review column\n",
        "df['review'] = df['review'].apply(simple_stemmer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA2RsIUenbGe"
      },
      "source": [
        "**Tokenization**\n",
        "\n",
        "Tokenization is the process of splitting paragraphs and sentences into smaller understandable parts (words).\n",
        "\n",
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MbCqVxg_F6jw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9912114-4a3c-4ee1-edba-ab14c0c835c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'is', 'a', 'test', 'sentence', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "word_tokenize('This is a test sentence.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omeXdqsFHm1M"
      },
      "source": [
        "**Removing stopwords**\n",
        "\n",
        "Stopwords are English words that do not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence. For example, the words like the, he, have etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mgIjbfZgEgNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baa126ce-b2b7-4335-906a-77406843391e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ],
      "source": [
        "# setting english stopwords\n",
        "stopword_list = nltk.corpus.stopwords.words('english')\n",
        "print(stopword_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jacr7HAjfILU"
      },
      "source": [
        "The above list of stopwords also contains the word \"not\", and its other forms such as don't, didn't, etc. We need them for correct sentiment classification.\n",
        "\n",
        "For example, consider a negative review \"*not a good movie*\", and if we remove 'not' from it then it becomes a positive review \"*a good movie*\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "U1uSxBepgdsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a7c294a-b22e-4c7b-a511-0d6344f13187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n"
          ]
        }
      ],
      "source": [
        "# Exclude 'not' and its other forms from the stopwords list\n",
        "\n",
        "updated_stopword_list = []\n",
        "\n",
        "for word in stopword_list:\n",
        "    if word=='not' or word.endswith(\"n't\"):\n",
        "        pass\n",
        "    else:\n",
        "        updated_stopword_list.append(word)\n",
        "\n",
        "print(updated_stopword_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9fH5HXfk8OJj"
      },
      "outputs": [],
      "source": [
        "# removing the stopwords\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    # splitting strings into tokens (list of words)\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        # filtering out the stop words\n",
        "        filtered_tokens = [token for token in tokens if token not in updated_stopword_list]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in updated_stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)\n",
        "    return filtered_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "H_OBq2crHXU5"
      },
      "outputs": [],
      "source": [
        "# apply function on review column\n",
        "df['review'] = df['review'].apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxWPUIt3QrBY"
      },
      "source": [
        "After cleaning the reviews, we now split the clean dataset into training and testing set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO5JxX7B8ita"
      },
      "source": [
        "### Split into training and testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juVRVeO6i3Xp"
      },
      "source": [
        "**Parameters in train_test_split**\n",
        "\n",
        "* arrays sequence of indexables with same length / shape (here, df.review and df.sentiment):\n",
        "Allowed inputs are lists, numpy arrays, scipy-sparse matrices or pandas dataframes.\n",
        "\n",
        "* test_size (float or int, default=None): The proportion of the dataset to include in the test split If train_size is also None, it will be set to 0.25.\n",
        "\n",
        "\n",
        "* RandomState:\n",
        "Controls the shuffling applied to the data before applying the split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gwGbAazvDVuB"
      },
      "outputs": [],
      "source": [
        "# Split into training and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.review, df.sentiment, test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "k_LwQzG3Ec3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7fc2d3-22d1-43f3-d804-79417e35ec20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000,)\n",
            "(10000,)\n",
            "(40000,)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG_BKf2kT9Ui"
      },
      "source": [
        "Let us see positive and negative words by using **WordCloud**.\n",
        "\n",
        "A word cloud (also called tag cloud or weighted list) is a visual representation of text data. Words are usually single words, and the importance of each is shown with font size or color.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upS9PJwNTYF5"
      },
      "outputs": [],
      "source": [
        "# Word cloud for positive review words\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "df_positive_review =  df[df['sentiment']=='positive']\n",
        "positive_text = ' '.join(review for review in df_positive_review.review)\n",
        "WC = WordCloud(width=1000, height=500, max_words=500, min_font_size=5)\n",
        "positive_words = WC.generate(positive_text)\n",
        "plt.imshow(positive_words, interpolation='bilinear')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word cloud for negative review words\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "df_negative_review =  df[df['sentiment']=='negative']\n",
        "negative_text = ' '.join(review for review in df_negative_review.review)\n",
        "WC = WordCloud(width=1000, height=500, max_words=500, min_font_size=5)\n",
        "negative_words = WC.generate(negative_text)\n",
        "plt.imshow(negative_words, interpolation='bilinear')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "loD-r5Hhnml_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOWWCH-gLJ0k"
      },
      "source": [
        "## Converting Text into numerical feature vectors:\n",
        "\n",
        "### 1. Bag of Words (based on word occurrence)\n",
        "\n",
        "In order to perform machine learning on text documents, we first need to turn the text content into numerical feature vectors.\n",
        "\n",
        "Bags of words is the most intuitive way to create such a representation:\n",
        "\n",
        "Assign a fixed integer id to each word occurring in any document of the training set (for instance by building a dictionary from words to integer indices).\n",
        "\n",
        "For each document $i$, count the number of occurrences of each word $w$ and store it in $X[i, j]$ as the value of feature $j$ where $j$ is the index of word $w$ in the dictionary.\n",
        "\n",
        "The bags of words representation implies that n_features is the number of distinct words in the corpus.\n",
        "\n",
        "<img src=\"https://cdn.iisc.talentsprint.com/AIandMLOps/Images/bag-of-words-example.png\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO52_AYgaMZa"
      },
      "source": [
        "#### Implementing Bag of Words using sklearn `Count Vectorizer`\n",
        "\n",
        "The `CountVectorizer` provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary.\n",
        "\n",
        "An encoded vector is returned with a length of the entire vocabulary and an integer count for the number of times each word appeared in the document. The vectors returned from a call to transform() will be sparse vectors, and we can transform them back to numpy arrays to look and better understand what is going on by calling the `toarray()` function.\n",
        "\n",
        "To know more about CountVectorizer, click [here](https://towardsdatascience.com/basics-of-countvectorizer-e26677900f9c)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilmOsl0ciO88"
      },
      "outputs": [],
      "source": [
        "# Count vectorizer\n",
        "cv = CountVectorizer(min_df=0, max_df=1, binary=False, ngram_range=(1,3))\n",
        "\n",
        "# transformed train reviews\n",
        "cv_train_reviews = cv.fit_transform(X_train)\n",
        "\n",
        "# transformed test reviews\n",
        "cv_test_reviews = cv.transform(X_test)\n",
        "\n",
        "print('CV_train:', cv_train_reviews.shape)\n",
        "print('CV_test:', cv_test_reviews.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN95C2gCM_Hc"
      },
      "source": [
        "### 2. TF-IDF (based on word frequencies)\n",
        "\n",
        "The issue with occurrence count is that longer documents will have higher average count values than shorter documents, even though they might talk about the same topics.\n",
        "\n",
        "To avoid these potential discrepancies it suffices to divide the number of occurrences of each word in a document by the total number of words in the document: these new features are called tf for Term Frequencies.\n",
        "\n",
        "Another refinement on top of tf is to downscale weights for words that occur in many documents in the corpus and are therefore less informative than those that occur only in a smaller portion of the corpus.\n",
        "\n",
        "This downscaling is called tf–idf for “Term Frequency times Inverse Document Frequency”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAavZUbLPNoY"
      },
      "source": [
        "#### Implementing TF-IDF with sklearn `TfidfVectorizer`\n",
        "\n",
        "It is used to convert text documents to matrix of tf-idf features.\n",
        "\n",
        "<img src=\"https://cdn.iisc.talentsprint.com/AIandMLOps/Images/tf-idf-formula.PNG\" width=500px>\n",
        "\n",
        "\n",
        "`TfidfVectorizer` is the base building block of many NLP pipelines. It is a simple technique to vectorize text documents — i.e. transform sentences into arrays of numbers — and use them in subsequent tasks.\n",
        "\n",
        "To know more about tf-idf, click [here]( https://cdn.iisc.talentsprint.com/CDS/TF-IDF.pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm4CdvwfLbLi"
      },
      "outputs": [],
      "source": [
        "# tfidf vectorizer\n",
        "tv = TfidfVectorizer(min_df=0, max_df=1, use_idf=True, ngram_range = (1,3))\n",
        "#transformed train reviews\n",
        "tfidf_train_reviews = tv.fit_transform(X_train)\n",
        "#transformed test reviews\n",
        "tfidf_test_reviews = tv.transform(X_test)\n",
        "print('Tfidf_train:', tfidf_train_reviews.shape)\n",
        "print('Tfidf_test:', tfidf_test_reviews.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne_S1VjfRH_S"
      },
      "source": [
        "### Modeling the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA2VTJIOMb1n"
      },
      "source": [
        "**Naïve Bayes’ Classifier**\n",
        "\n",
        "Bayesian network classifiers are a popular supervised\n",
        "classification paradigm. The Naïve Bayes’ classifier is a probabilistic\n",
        "classifier based on the Bayes’ theorem, considering a 'naive'\n",
        "independence assumption.\n",
        "It is a popular(baseline) method for text categorization, with word frequencies as the feature.\n",
        "\n",
        "An advantage of Naïve Bayes’ is that it\n",
        "only requires a small amount of training data to\n",
        "estimate the parameters necessary for classification. Despite its simplicity and strong assumptions, the\n",
        "Naïve Bayes’ classifier has been proven to work\n",
        "satisfactorily in many domains. Bayesian classification\n",
        "provides practical learning algorithms and prior knowledge and observed data can be combined. In Naïve Bayes’ technique, the basic idea is to find the\n",
        "probabilities of categories given a text document by\n",
        "using the joint probabilities of words and categories. It is based on the assumption of word independence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9oco2hkRXP3"
      },
      "source": [
        "Naive Bayes classifier for multinomial models.\n",
        "\n",
        "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.\n",
        "\n",
        "To know more, click [here](https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkqhHOOpjxni"
      },
      "outputs": [],
      "source": [
        "# training the model\n",
        "mnb = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
        "\n",
        "# fitting the NaiveBayes for count vectorizer\n",
        "mnb_cv = mnb.fit(cv_train_reviews, y_train)\n",
        "\n",
        "print('MultinomialNB for Count Vectorizer :', mnb_cv)\n",
        "\n",
        "# fitting the NaiveBayes for tfidf features\n",
        "mnb_tfidf = mnb.fit(tfidf_train_reviews, y_train)\n",
        "\n",
        "print('MultinomialNB for tf-idf :', mnb_tfidf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU0rl3M8n3_d"
      },
      "source": [
        "**Optional deeper dive:**\n",
        "\n",
        "Naive Bayes model parameters:\n",
        "\n",
        "* *alpha*:\n",
        "Additive smoothing parameter (0 for no smoothing). In statistics, additive smoothing, also called Laplace smoothing, is a technique used to smooth categorical data. Given a set of observation counts ${\\textstyle {\\mathbf {x} \\ =\\ \\left\\langle x_{1},\\,x_{2},\\,\\ldots ,\\,x_{d}\\right\\rangle }}$ from a $d$-dimensional multinomial distribution with $N$ trials, a \"smoothed\" version of the counts gives the estimator:\n",
        "$${\\hat {\\theta }}_{i}={\\frac {x_{i}+\\alpha }{N+\\alpha d}}\\qquad (i=1,\\ldots ,d),$$\n",
        "where the smoothed count ${\\textstyle {{\\hat {x}}_{i}=N{\\hat {\\theta }}_{i}}}$ and the \"pseudocount\" $α > 0$ is a smoothing parameter. $α = 0$ corresponds to no smoothing.\n",
        "\n",
        "* *fit_prior*:\n",
        "Whether to learn class prior probabilities or not. If false, a uniform prior will be used.\n",
        "\n",
        "* *class_prior*:\n",
        "Prior probabilities of the classes. If specified the priors are not adjusted according to the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDp3YW0fSAtO"
      },
      "source": [
        "**Model performance on test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnXIgKkLR2uM"
      },
      "outputs": [],
      "source": [
        "# predicting the model for CountVectorizer\n",
        "mnb_cv_predict = mnb.predict(cv_test_reviews)\n",
        "print('predictions for Count Vectorizer :', mnb_cv_predict)\n",
        "\n",
        "# predicting the model for tfidf features\n",
        "mnb_tfidf_predict = mnb.predict(tfidf_test_reviews)\n",
        "print('predictions for tf-idf :', mnb_tfidf_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUnQOGpoShcz"
      },
      "source": [
        "**Accuracy of Model**\n",
        "\n",
        "It is the ratio of number of correct classifications to the total number of input samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1EHCAnWSRZ1"
      },
      "outputs": [],
      "source": [
        "# accuracy score for count vectorizer\n",
        "mnb_cv_score = accuracy_score(y_test, mnb_cv_predict)\n",
        "print(\"mnb_cv_score :\", mnb_cv_score)\n",
        "\n",
        "# accuracy score for tf-idf\n",
        "mnb_tfidf_score = accuracy_score(y_test, mnb_tfidf_predict)\n",
        "print(\"mnb_tfidf_score :\", mnb_tfidf_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEih5xUNTFX3"
      },
      "source": [
        "**Plotting the confusion matrix**\n",
        "\n",
        "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known.\n",
        "\n",
        "A confusion matrix, in predictive analytics, is a square matrix that tells us the rate of false positives, false negatives, true positives and true negatives for a test or predictor. We can make a confusion matrix if we know both the predicted values and the true values for a sample set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWeRBlGBmIHB"
      },
      "outputs": [],
      "source": [
        "# confusion matrix for count vectorizer\n",
        "cm_cv = confusion_matrix(y_test, mnb_cv_predict, labels=['positive', 'negative'])\n",
        "print('confusion matrix for count vectorizer :\\n', cm_cv)\n",
        "\n",
        "# confusion matrix for tf-idf\n",
        "cm_tfidf = confusion_matrix(y_test,mnb_tfidf_predict, labels=['positive','negative'])\n",
        "print('confusion matrix for tf-idf :\\n', cm_tfidf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXQYvbik134w"
      },
      "source": [
        "## Gradio Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9LGFxtQjwxv"
      },
      "source": [
        "Gradio is an open-source python library that allows us to quickly create easy-to-use, customizable UI components for our ML model, any API, or any arbitrary function in just a few lines of code. We can integrate the GUI directly into the Python notebook, or we can share the link with anyone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wl0ngdnKjKHH"
      },
      "outputs": [],
      "source": [
        "!pip -qq install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XwCJSdDDVVU"
      },
      "outputs": [],
      "source": [
        "import gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U41iWl1H14kt"
      },
      "outputs": [],
      "source": [
        "# Function for preprocessing of text\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "    text = denoise_text(text)\n",
        "    text = remove_special_characters(text)\n",
        "    text = simple_stemmer(text)\n",
        "    text = remove_stopwords(text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTEAHUtr0vm1"
      },
      "outputs": [],
      "source": [
        "# Function to predict label for a review\n",
        "\n",
        "def predict_review_label(text, vectorizer_method):\n",
        "\n",
        "    processed_text = preprocess_text(text)\n",
        "\n",
        "    if vectorizer_method == 'CountVectorizer':\n",
        "        review = cv.transform([processed_text])\n",
        "        pred = mnb_cv.predict(review)\n",
        "    if vectorizer_method == 'TFIDFVectorizer':\n",
        "        review = tv.transform([processed_text])\n",
        "        pred = mnb_tfidf.predict(review)\n",
        "    else:\n",
        "        review = cv.transform([processed_text])\n",
        "        pred = mnb_cv.predict(review)\n",
        "\n",
        "    return pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZG4q5-9I6n0x"
      },
      "outputs": [],
      "source": [
        "# Testing a review\n",
        "predict_review_label(\"It was a good movie, really enjoyed it a lot.\", 'CountVectorizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b17nuGAm-hym"
      },
      "outputs": [],
      "source": [
        "# Testing a review\n",
        "predict_review_label(\"Was very bad, I was barely able to understand the concepts.\", 'TFIDFVectorizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAWKOcY25sDA"
      },
      "outputs": [],
      "source": [
        "# Dropdown choices\n",
        "in_vectorizer_dropdown = gradio.Dropdown(['CountVectorizer', 'TFIDFVectorizer'], type=\"value\", label='Choose a Method to Vectorize')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy_0yXHI7fs4"
      },
      "outputs": [],
      "source": [
        "# Input from user\n",
        "in_review = gradio.Textbox(lines=2, placeholder=None, value=\"review\", label='Enter Review Text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlLlAp4E8pew"
      },
      "outputs": [],
      "source": [
        "# Output prediction\n",
        "out_label = gradio.Textbox(type=\"text\", label='Predicted Review Label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpRnUY5w551-"
      },
      "outputs": [],
      "source": [
        "# Gradio interface to generate UI link\n",
        "\n",
        "iface = gradio.Interface(fn = predict_review_label,\n",
        "                         inputs = [in_review, in_vectorizer_dropdown],\n",
        "                         outputs = [out_label])\n",
        "\n",
        "iface.launch(share = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2eQkcvnvntC"
      },
      "source": [
        "Click on the link generated above to see UI."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}